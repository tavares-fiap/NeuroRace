# NeuroRace: Plataforma de Neurofeedback Gamificado

**NeuroRace** Ã© uma plataforma completa que transforma a concentraÃ§Ã£o, medida por dados de EEG, em uma competiÃ§Ã£o de corrida gamificada. Desenvolvido para ser uma das atraÃ§Ãµes de destaque na **IniciaÃ§Ã£o CientÃ­fica do Next FIAP**, o projeto vai alÃ©m de um simples jogo, incorporando um **pipeline de dados automatizado** para anÃ¡lise de performance cognitiva em tempo real.

Os jogadores competem em um runner de tela dividida, onde a velocidade Ã© controlada pelo seu nÃ­vel de foco. Ao final de cada corrida, a plataforma analisa o desempenho, gera mais de 10 KPIs cognitivos e fornece um **feedback de coaching personalizado por IA**, permitindo que os jogadores entendam e melhorem sua performance mental.

![NeuroRace in Action](./images/game.png)

---

## ğŸ§© Arquitetura Completa

O NeuroRace opera com uma arquitetura de microsserviÃ§os orientada a eventos, projetada para coleta, processamento e anÃ¡lise de dados em tempo real.

```mermaid
graph TD
    subgraph "PC do Jogador"
        A1[EEG: Simulador / NeuroSky] --> B1[Acquisition Service];
        C[Jogo Unreal Engine] -- "Eventos (inÃ­cio, colisÃ£o, fim)" --> D[Data Broker];
    end

    subgraph "Backend (ServiÃ§os Docker)"
        B1 -- "Dados EEG (eSense)" --> D;
        D -- Broadcast --> E[Raw Data Collector];
        D -- Broadcast --> C;
        D -- Broadcast --> F[Pipeline Worker];
    end
    
    subgraph "Cloud (Firebase)"
        G[Firestore DB];
    end

    E -- Salva --> H{"Camada Raw (.jsonl)"};
    F -- "Ouve 'hasFinished'" --> D;
    F -- LÃª --> H;
    F -- "Processa e Salva" --> I{"Camada Trusted (.parquet)"};
    F -- LÃª --> I;
    F -- "Calcula KPIs e Salva" --> J{"Camada Refined (.json)"};
    F -- "Envia Dados" --> G;

    style A1 fill:#cde4ff
    style C fill:#cde4ff
    style G fill:#ffe8cc
```

**Componentes Principais:**
1.  **Fonte de EEG** (`simulator.py` ou NeuroSky): Gera os dados brutos de ondas cerebrais.
2.  **ServiÃ§o de AquisiÃ§Ã£o** (`acquisition_service.py`): LÃª, enriquece e publica os dados de EEG no Broker.
3.  **Data Broker** (`index.js`): Um hub Socket.IO que distribui todos os eventos (`eSense`, `gameEvent`) em tempo real.
4.  **Coletor da Camada Raw** (`raw_data_collector`): Ouve o broker e salva todos os dados brutos, sem filtro, em arquivos `.jsonl`. Ã‰ a porta de entrada do nosso pipeline de dados.
5.  **Pipeline Worker** (`pipeline_worker`): O cÃ©rebro do nosso backend. Este serviÃ§o orquestrador Ã© acionado pelo fim de uma corrida e executa automaticamente todo o pipeline de dados.

---

## ğŸ”„ Fluxo de Dados Automatizado

O coraÃ§Ã£o do projeto Ã© um pipeline de dados automatizado que transforma dados brutos em insights acionÃ¡veis.

```mermaid
flowchart TD
    A["Jogo termina e emite 'hasFinished'"] --> B[Pipeline Worker Ã© acionado];
    B --> C["1. ETL: Raw -> Trusted<br>(LÃª .jsonl, limpa, unifica e salva como .parquet)"];
    C --> D["2. Processamento: Trusted -> Refined<br>(LÃª .parquet, calcula +10 KPIs)"];
    D --> E["3. Data Science & IA<br>(Gera feedback de partida e evoluÃ§Ã£o)"];
    E --> F["4. Carga no Firebase<br>(Salva KPIs e feedback no Firestore)"];
    F --> G["Fim: Dados disponÃ­veis para o Dashboard"];

    style A fill:#d4edda,stroke:#155724
    style G fill:#d4edda,stroke:#155724
```

---

## ğŸ“ Estrutura de Pastas Atualizada

```text
.
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ data_broker/
â”œâ”€â”€ data_pipeline/
â”‚   â”œâ”€â”€ data/                 # Armazenamento local dos dados
â”‚   â”‚   â”œâ”€â”€ raw_data/
â”‚   â”‚   â”œâ”€â”€ trusted_data/
â”‚   â”‚   â””â”€â”€ refined_data/
â”‚   â”œâ”€â”€ pipeline_worker/      # Orquestrador e processador (ETL + Refined)
â”‚   â”œâ”€â”€ raw_data_collector/   # Coletor de dados brutos
â”‚   â””â”€â”€ secrets/              # Armazena as credenciais do Firebase
â”œâ”€â”€ eeg_acquisition/
â”œâ”€â”€ images/
â”œâ”€â”€ test_emitter.py           # Script para simular uma corrida completa
â””â”€â”€ ...
```

---

## âš™ï¸ Como Rodar (Ambiente de SimulaÃ§Ã£o Local)

O projeto utiliza **Docker Compose Profiles** para gerenciar diferentes cenÃ¡rios de execuÃ§Ã£o. O perfil principal para desenvolvimento e teste Ã© o `sim-local`.

1.  **PrÃ©-requisitos:**
    *   Docker e Docker Compose instalados.

2.  **Build e ExecuÃ§Ã£o:**
    Na raiz do projeto, execute o comando para subir todos os serviÃ§os do perfil de simulaÃ§Ã£o local (dois simuladores no mesmo PC).
    ```bash
    docker compose --profile sim-local up --build -d
    ```

Isso iniciarÃ¡ todos os serviÃ§os necessÃ¡rios, incluindo os simuladores, o broker e todo o pipeline de dados.

---

## ğŸ§ª Testando o Pipeline de Ponta a Ponta

Para validar toda a arquitetura, do envio de dados atÃ© o salvamento no Firebase, utilizamos o `test_emitter.py`. Este script simula uma corrida completa, com mÃºltiplos eventos, e aciona o pipeline automatizado.

1.  **Monitore o Orquestrador:**
    Em um terminal, observe os logs do `pipeline_worker` em tempo real. Ele estarÃ¡ aguardando o fim de uma corrida.
    ```bash
    docker compose logs -f pipeline_worker
    ```

2.  **Execute o Emissor de Teste:**
    Em outro terminal, execute o script.
    ```bash
    python test_emitter.py
    ```

3.  **Observe a MÃ¡gica:**
    Volte ao terminal do `pipeline_worker`. VocÃª verÃ¡ o pipeline ser acionado e executar todas as etapas: ETL, cÃ¡lculo de KPIs e o envio final para o Firebase, incluindo a atualizaÃ§Ã£o dos perfis de usuÃ¡rio. Ao final, os dados estarÃ£o disponÃ­veis no seu console do Firestore.

---

## ğŸ’¾ A Pilha de Dados: Do Bruto ao Insight

Nossa arquitetura de dados Ã© dividida em camadas, culminando no Firestore para consumo pelo front-end.

*   **Camada Raw (`.jsonl`):** Armazenamento de todos os eventos e dados de EEG brutos, sem filtros. A "memÃ³ria" completa de cada corrida.
*   **Camada Trusted (`.parquet`):** Dados limpos, estruturados, unificados e enriquecidos. A "fonte Ãºnica da verdade" para qualquer anÃ¡lise.
*   **Camada Refined (`.json`):** O sumÃ¡rio final, contendo os KPIs e o feedback do coach para cada jogador.

**Destino Final: Firestore**
O pipeline alimenta trÃªs coleÃ§Ãµes principais no Firestore, prontas para o front-end:
1.  `/sessions/{sessionId}`: ContÃ©m os KPIs detalhados e o **feedback da partida** para cada jogador daquela sessÃ£o.
2.  `/users/{userId}`: O perfil de cada jogador, com suas estatÃ­sticas agregadas (total de vitÃ³rias, recordes) e o **feedback de evoluÃ§Ã£o** dinÃ¢mico.
3.  `/global_stats/summary`: Um documento Ãºnico com estatÃ­sticas globais (mÃ©dias, percentis) de todos os jogadores, usado para gerar contexto e comparaÃ§Ãµes em tempo real.

---

## ğŸ§  MÃ©tricas e Coach Virtual (IA)

O pipeline calcula mais de 10 KPIs para cada jogador, incluindo:
*   **TZF (Tempo em Zona de Foco):** % do tempo em alta concentraÃ§Ã£o.
*   **CVF (ConsistÃªncia do Foco):** NÃ­vel de estabilidade da atenÃ§Ã£o.
*   **LFO (LatÃªncia para o Foco):** Tempo de recuperaÃ§Ã£o mental apÃ³s um erro.
*   **TendÃªncia de Fadiga:** AnÃ¡lise da carga mental ao longo da corrida.

Com base nesses dados, nosso **Coach Virtual** gera dois tipos de feedback: uma anÃ¡lise da performance na partida e um relatÃ³rio sobre a evoluÃ§Ã£o do jogador ao longo do tempo.

---

## ğŸ® Jogo (Unreal) â€” Status & IntegraÃ§Ã£o

**Status:** em desenvolvimento. O jogo Ã© um **runner** com **tela dividida** e obstÃ¡culos. JÃ¡ **recebe dados simulados** do Broker e ajusta a velocidade dos personagens conforme `attention`.

**ConexÃ£o esperada (lado do jogo):** cliente Socket.IO para `ws://<HOST_DO_BROKER>:3000`, escutando o evento:

```json
{ "player": 1 | 2, "attention": <float> }
```

> ![Jogo â€” Tela dividida](./images/game2.gif)
> *Legenda: Imagens do jogo em desenvolvimento.*

---

## ğŸ“Š Dashboard â€” Status & DemonstraÃ§Ãµes

**Status:** protÃ³tipo em teste (UI/estÃ©tica em definiÃ§Ã£o) â€” **nÃ£o estÃ¡ neste repositÃ³rio** ainda.

> ![Dashboard â€” UI A](./images/dashboard1.gif)
> *Legenda: Prototipo do dashboard*

---

## ğŸ—ºï¸ PrÃ³ximos Passos

Com a infraestrutura de dados completa e automatizada, o foco do projeto se volta para:
1.  **Front-end & Dashboard:** Construir as interfaces para visualizar os rankings, histÃ³ricos de corridas e os feedbacks do coach, consumindo os dados diretamente do Firestore.
2.  **IntegraÃ§Ã£o com o Jogo:** Portar a lÃ³gica do `test_emitter.py` para o cliente do jogo em Unreal Engine, para que ele emita os eventos reais.
3.  **Deployment em ProduÃ§Ã£o:** Migrar os serviÃ§os Docker para um ambiente de nuvem para garantir a disponibilidade durante o evento Next FIAP.

---

## ğŸ“„ LicenÃ§a

Este projeto estÃ¡ sob a [MIT License](LICENSE).
