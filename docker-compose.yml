
services:
  broker:
    build: ./data_broker
    ports: 
      - "3000:3000"

  simulator-a:
    build: ./eeg_acquisition
    environment:
      ACQ_PORT: ${ACQ_PORT_A}
      PACKET_INTERVAL: ${PACKET_INTERVAL_A}
    command: python simulator.py
    ports: 
      - "13854:13854"

  simulator-b:
    build: ./eeg_acquisition
    environment:
      ACQ_PORT: ${ACQ_PORT_B}
      PACKET_INTERVAL: ${PACKET_INTERVAL_B}
    command: python simulator.py
    ports:
      - "13855:13855"

  acquisition-a:
    build: ./eeg_acquisition
    extra_hosts:
      - "host.docker.internal:host-gateway"
    environment:
      PLAYER_ID: ${PLAYER_ID_A}
      ACQ_PORT: ${ACQ_PORT_A}
      BROKER_URL: ${BROKER_URL}
      POOR_SIGNAL_LEVEL_THRESHOLD: ${POOR_SIGNAL_LEVEL_THRESHOLD}
      EEG_HOST: ${EEG_HOST_A}
    command: python acquisition_service.py
    depends_on: 
      - broker
      - simulator-a

  acquisition-b:
    build: ./eeg_acquisition
    extra_hosts:
      - "host.docker.internal:host-gateway"
    environment:
      PLAYER_ID: ${PLAYER_ID_B}
      ACQ_PORT: ${ACQ_PORT_B}
      BROKER_URL: ${BROKER_URL}
      POOR_SIGNAL_LEVEL_THRESHOLD: ${POOR_SIGNAL_LEVEL_THRESHOLD}
      EEG_HOST: ${EEG_HOST_B}
    command: python acquisition_service.py
    depends_on: 
      - broker
      - simulator-b
  
  test-client:
    build: ./test_client
    environment:
      BROKER_URL: "http://broker:3000"
    depends_on:
      - broker

  raw-data-collector:
    build: ./data_pipeline/raw_data_collector
    environment:
      BROKER_URL: "http://broker:3000"
      RAW_DATA_PATH: "/data/raw_data" # ATUALIZADO
    volumes:
      # Mapeia a pasta `data` local para a pasta `/data` do container
      - ./data_pipeline/data:/data # ATUALIZADO
    depends_on:
      - broker
    command: sh -c "sleep 5 && python -u collector.py"

  # etl_processor:
  #   build: ./data_pipeline/etl_processor
  #   environment:
  #     RAW_DATA_PATH: "/data/raw_data"
  #     TRUSTED_DATA_PATH: "/data/trusted_data"
  #   volumes:
  #     # Compartilha EXATAMENTE O MESMO volume
  #     - ./data_pipeline/data:/data # ATUALIZADO
    
  # refined_processor:
  #   build: ./data_pipeline/refined_processor
  #   environment:
  #     TRUSTED_DATA_PATH: "/data/trusted_data"
  #     REFINED_DATA_PATH: "/data/refined_data"
  #     GOOGLE_APPLICATION_CREDENTIALS: "/app/firebase-credentials.json"
  #   volumes:
  #     # Compartilha o mesmo volume novamente
  #     - ./data_pipeline/data:/data
  #     - ./data_pipeline/secrets/firebase-credentials.json:/app/firebase-credentials.json
    

  pipeline-worker:
    build: ./data_pipeline/pipeline_worker
    environment:
      BROKER_URL: "http://broker:3000"
      RAW_DATA_PATH: "/data/raw_data"
      TRUSTED_DATA_PATH: "/data/trusted_data"
      REFINED_DATA_PATH: "/data/refined_data"
      GOOGLE_APPLICATION_CREDENTIALS: "/app/firebase-credentials.json"
    volumes:
      # Mapeia a pasta de dados e a de segredos
      - ./data_pipeline/data:/data
      - ./data_pipeline/secrets/firebase-credentials.json:/app/firebase-credentials.json
    depends_on:
      - broker

  # dashboard:
  #   build: ./dashboard

  #   ports:
  #     - "8000:80"

  #   depends_on:
  #     - broker

# volumes:
#   db_data:
